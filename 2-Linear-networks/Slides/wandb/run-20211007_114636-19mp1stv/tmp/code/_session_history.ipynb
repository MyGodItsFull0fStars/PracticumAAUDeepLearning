{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09126a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef7581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc69d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.sdk.wandb_run.Run at 0x7f74b54535e0>"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">graceful-sea-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ingambe/course\" target=\"_blank\">https://wandb.ai/ingambe/course</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ingambe/course/runs/19mp1stv\" target=\"_blank\">https://wandb.ai/ingambe/course/runs/19mp1stv</a><br/>\n",
       "                Run data is saved locally in <code>/home/ingambe/DeepLearningCourse/2-Linear-networks/Slides/wandb/run-20211007_114636-19mp1stv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project='course') # specify the project of the current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801f1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2, -3.4, 5, 6])\n",
    "true_b = 2.4\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cc37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 32\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a1471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-7.4017e-01, -3.2112e-01,  3.9978e-01,  1.8021e+00],\n",
      "         [ 6.2178e-01,  2.1092e+00, -1.5599e-01, -1.1109e-01],\n",
      "         [ 8.6601e-01,  7.7299e-01, -6.9430e-01, -1.0669e+00],\n",
      "         [ 1.2534e+00, -3.8269e-01, -8.7639e-01, -1.5491e+00],\n",
      "         [-8.7189e-01,  5.9789e-02, -2.2750e+00, -5.6527e-01],\n",
      "         [-4.2654e-01,  2.1044e-01,  7.4166e-01, -5.2512e-01],\n",
      "         [-4.7578e-01,  1.7765e+00,  2.9422e+00, -3.1139e-01],\n",
      "         [-1.1495e-01, -4.7511e-01,  2.9386e-02,  9.1964e-01],\n",
      "         [-3.2373e-02,  1.2088e-02, -1.0838e+00, -3.6136e-01],\n",
      "         [-1.5382e+00,  1.4769e-01, -4.0155e-01, -2.5135e+00],\n",
      "         [-2.2676e+00,  6.8901e-01,  6.0846e-02,  2.0099e+00],\n",
      "         [-9.8130e-01, -5.4044e-01,  1.5668e+00,  6.2797e-01],\n",
      "         [ 2.7403e+00,  7.2366e-01, -4.6050e-01, -4.6123e-01],\n",
      "         [ 6.8973e-01, -2.9694e-02, -2.5740e-02,  1.4053e+00],\n",
      "         [ 1.6242e-02, -1.1006e+00, -2.0717e-01, -8.4463e-01],\n",
      "         [ 8.0265e-01, -2.0285e-01,  1.9061e+00, -8.8684e-01],\n",
      "         [-3.8099e-01, -6.5606e-01,  2.2499e+00, -7.6969e-01],\n",
      "         [ 2.2250e-01,  2.6604e-01, -1.3899e+00, -5.5899e-02],\n",
      "         [-1.2137e+00,  6.5163e-01,  1.5027e+00,  6.4754e-01],\n",
      "         [-9.5633e-01,  6.3453e-01,  7.6902e-02,  1.0464e+00],\n",
      "         [-2.8393e-01,  8.3274e-02,  1.2371e+00,  9.4886e-01],\n",
      "         [-2.0382e-03,  1.8338e+00,  1.0005e-02, -5.2243e-01],\n",
      "         [-9.2149e-02, -1.5300e+00,  3.3279e-01, -1.1502e-01],\n",
      "         [ 1.1762e+00,  4.8479e-01,  1.0758e+00,  1.1465e+00],\n",
      "         [-1.6272e+00, -3.7224e-01, -3.3762e+00,  5.9335e-01],\n",
      "         [ 1.9047e+00,  1.5482e+00,  9.3145e-01,  6.8041e-01],\n",
      "         [-1.4950e+00, -1.3746e+00,  1.5222e-01, -5.0278e-01],\n",
      "         [ 1.6679e+00,  1.2035e-01, -4.9902e-01,  2.4265e-01],\n",
      "         [ 7.1454e-01,  7.2537e-01,  2.0135e-01, -4.3270e-01],\n",
      "         [ 2.2733e-01,  3.9134e-01,  4.7487e-02,  7.7222e-01],\n",
      "         [-1.1626e+00, -1.1970e+00,  3.8836e-02, -1.2144e-01],\n",
      "         [-5.3844e-01, -2.5816e-01,  2.8637e-01,  6.7680e-01]]),\n",
      " tensor([[ 14.8251],\n",
      "         [ -4.9615],\n",
      "         [ -8.3756],\n",
      "         [ -7.4720],\n",
      "         [-14.3305],\n",
      "         [  1.3820],\n",
      "         [  8.2597],\n",
      "         [  9.4431],\n",
      "         [ -5.3000],\n",
      "         [-18.2670],\n",
      "         [  7.8852],\n",
      "         [ 13.8703],\n",
      "         [  0.3635],\n",
      "         [ 12.1702],\n",
      "         [  0.0796],\n",
      "         [  8.9241],\n",
      "         [ 10.5132],\n",
      "         [ -5.3419],\n",
      "         [  9.1608],\n",
      "         [  4.9919],\n",
      "         [ 13.4334],\n",
      "         [ -6.9155],\n",
      "         [  8.4250],\n",
      "         [ 15.3426],\n",
      "         [-12.9300],\n",
      "         [  9.7048],\n",
      "         [  1.8444],\n",
      "         [  4.2941],\n",
      "         [ -0.2381],\n",
      "         [  6.4107],\n",
      "         [  3.6041],\n",
      "         [  7.6744]])]"
     ]
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a44fdcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `nn` is an abbreviation for neural networks\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5369141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0146,  0.0074,  0.0049, -0.0058]])"
     ]
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01) # net[0] is the first layer\n",
    "net[0].bias.data.fill_(0)\n",
    "net[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "475715d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3785, -0.4744, -0.6180,  0.5488]])"
     ]
    }
   ],
   "source": [
    "def _weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.zero_()\n",
    "        \n",
    "net.apply(_weights_init)\n",
    "net[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1cc0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca858f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<wandb.wandb_torch.TorchGraph at 0x7f74fdfd1a00>]"
     ]
    }
   ],
   "source": [
    "wandb.watch(net, log=\"all\", criterion=loss, log_freq=1,  log_graph=(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c63c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(net.parameters(), lr=3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6359b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3785, -0.4744, -0.6180,  0.5488]], requires_grad=True)"
     ]
    }
   ],
   "source": [
    "next(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007d20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X), y)\n",
    "        optim.zero_grad() # please don't forget!\n",
    "        l.backward() # remember: You need to tell wrt to what the gradient is computed\n",
    "        optim.step() # do a step in the gradient direction\n",
    "    with torch.no_grad():\n",
    "        l = loss(net(features), labels) \n",
    "        print(f'epoch {epoch + 1}, loss {l.item()}')\n",
    "        wandb.log({'loss': l.item()}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f797e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = net[0].weight.data\n",
    "print('error in estimating w:', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('error in estimating b:', true_b - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96c66a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'my_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0601de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[ 2.0003, -3.4006,  5.0000,  5.9998]])),\n",
      "             ('0.bias', tensor([2.3996]))])"
     ]
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "963094db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3996])"
     ]
    }
   ],
   "source": [
    "net[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d3f36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ec603af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "291af02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project='course') # specify the project of the current run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
